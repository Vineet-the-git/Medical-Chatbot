{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9c60e4-17fd-4f6a-829b-ac228fc4e4da",
   "metadata": {},
   "source": [
    "This notebook will have a fully functional and better conversational chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2ab8da-44dc-4599-88b4-2a2285bcebeb",
   "metadata": {},
   "source": [
    "### Part 1: Load embedding model, llm and create a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b8e659-d359-44fe-b334-52a6c2baff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10105cdc-58fb-4168-b299-679f5a6f2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download the embedding model\n",
    "def download_embedding_model():\n",
    "    \"\"\"\n",
    "    Function to download the embedding model\n",
    "    \n",
    "    Args:\n",
    "    model_name : str : Name of the model to download\n",
    "    \n",
    "    Returns:\n",
    "    embeddings : object : Embedding model object\n",
    "    \"\"\"\n",
    "    \n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"NeuML/pubmedbert-base-embeddings\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314d5e28-19f9-40af-9b21-61c8c12b4ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinee\\Desktop\\Challenges\\Medical-Chatbot\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\vinee\\Desktop\\Challenges\\Medical-Chatbot\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "700253e3-2651-4aff-88df-5cba97300ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PINECONE_API_KEY = \"e485b6b8-b6f4-4e95-b3b8-081584058e80\"\n",
    "PINECONE_API_ENV = \"us-east-1\"\n",
    "PINECONE_INDEX_NAME = \"medicine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6f6e66-fce0-4b9e-84be-b2f9d0299a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStore = PineconeVectorStore(index_name=PINECONE_INDEX_NAME, embedding=embeddings)\n",
    "retriever = vectorStore.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63af4af-1396-4f3e-b136-d729eb823d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"../models/BioMistral-7B.Q4_K_M.gguf\"\n",
    "llm = LlamaCpp(model_path= \n",
    "local_llm,temperature=0.3,max_tokens=4096,top_p=1,n_ctx= 4096, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772efc2d-688e-44ee-89d5-ef49bed211e0",
   "metadata": {},
   "source": [
    "## Create the retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25c59a8-6f31-4be8-848a-1cea7263505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598e74e8-ddb2-4672-bb61-e3fed943a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_search_query = ChatPromptTemplate.from_messages([\n",
    "MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "(\"user\",\"{input}\"),\n",
    "(\"user\",\"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "\n",
    "prompt_get_answer = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"Answer the user's questions based in detail on the following context. If you need more information or clarification, ask for it:\\\\n\\\\n{context}\"),\n",
    "MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "(\"user\",\"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532338d3-a3ba-43da-893b-8bc446be1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt_search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b65de450-da35-4ee1-a3f5-3e7e034378ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_chain=create_stuff_documents_chain(llm,prompt_get_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fb6144e-6f3e-4c8e-8533-b1af04348b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01147182-738e-460a-81c5-ab6eb88bdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat history\n",
    "chat_history = [SystemMessage(content=\"You are a knowledgeable medical chatbot that provides information on common medical conditions based on user symptoms. Offer potential diagnoses, preventive measures, and advice clearly and accurately.\")]\n",
    "\n",
    "# Function to handle a single turn of the conversation\n",
    "def handle_conversation(input_text):\n",
    "    global chat_history\n",
    "    # Invoke the retrieval chain\n",
    "    response = retrieval_chain.invoke({\n",
    "        \"chat_history\": chat_history,\n",
    "        \"input\": input_text\n",
    "    })\n",
    "\n",
    "    print(response)\n",
    "    \n",
    "    # Extract and print the response\n",
    "    answer = response['answer']\n",
    "    print(\"AI:\", answer)\n",
    "    \n",
    "    # Update chat history with the user's input and AI's response\n",
    "    chat_history.append(HumanMessage(content=input_text))\n",
    "    chat_history.append(AIMessage(content=answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec159d6-8c61-422c-b487-b32534213675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start chatting with the bot! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  What is diabetes mellitus and how to prevent it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [SystemMessage(content='You are a knowledgeable medical chatbot that provides information on common medical conditions based on user symptoms. Offer potential diagnoses, preventive measures, and advice clearly and accurately.')], 'input': 'What is diabetes mellitus and how to prevent it?', 'context': [Document(page_content='. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 421'), Document(page_content='::· .. :\" \"\\'\\'. \", .·: . ::·. ... 1 \" £. :::· ��,��,��r��1 ����!��� .�-=\\'.��:=;=··�=-\\n�1·--t-i� :.. :�\"\\' ;.::,� ----\\'-· -\\'-\\' .:.�...._-:-: ---:�..... ; . . . ........ \\n1-- ,-.'), Document(page_content='25 ..... ,,. \\'- -- I \\'\\\\/• · \\'\\\\, ....... �·, .... \\'-.::..-7 --\" ;�·/ \"\\\\\\\\\\\\1,1•• 10, ... ;<� .. �:::-·-· ;;--·-Q// \\'\"\\'\\\\ {\\\\\\\\V\\\\ I \\n\\'-. \\'°\\'.;.\\'\" ...... -�--_....I V \\'.t�\\\\, I 3 ·-. \\'\\'-....:: • .i._-:.·-:.··············\\'/ /,\\\\··-.,.\\\\\\\\\\\\\\' \\\\ ·. - ...... _ ,. ,\\'\\\\i\\'�.')], 'answer': ''}\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "# Main loop to continuously take user input and update chat history\n",
    "print(\"Start chatting with the bot! Type 'exit' to end the conversation.\")\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    handle_conversation(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d248641c-2d88-4051-951f-9b438c4deab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
